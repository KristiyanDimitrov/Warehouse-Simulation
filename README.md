							DEMO VIDEO
		This is not the final product, it is a MID-WAY development demo with a lot of bugs for interviewing purposes.
					  https://www.youtube.com/watch?v=AduL7gr50jU



Simulation software for conducting work environment tests on the pickers of units in a warehouse.





Abstract
Warehouses nowadays are complex systems that undergo a lot of changes in the way they operate. In order to validate those changes, management have to perform a test that is executed on ground level during worktime. Carrying out such tests could seriously affect the productivity and safety of the process. We are going to explore the implication of a simulation software for the picking process and if it could provide a safe-zone testing-ground where the impact can be observed visually and statistically. As a proof of concept this research is not aiming at a completely accurate simulation, that produces the same results as a warehouse, but rather a depiction of how certain changes affect the process. The goal is not necessarily to omit the ground level test, but rather to provide additional information about outcomes and interactions when a new aspect is introduced, thus aiding the decision making and reasons to conduct a ground level test. 
The simulation software provides means of altering the layout of the warehouse (shelves, drop-zones etc.) and rules of interaction (rules of travel, safe distance between workers etc.) which allows the company to “clone their gears” of their working environment. For the reason of sustaining the individual aspect of each worker, the pickers are represented by autonomous agents with global path finding methods. They follow the rules which the workers must abide by and are able to interact with other dynamic objects (other pickers). The heterogeneous movements of the pickers are depicted on a two-dimensional grid that represent the layout. The confirmed viability of the simulation is dictated by its ability to perform a full run that adequately depicts the picking process statistically and visually.





	
Introduction 
What are ground level tests and why are they a risk.
Nowadays warehouses are complex systems composed of different departments that can’t fully function without each other. That is why every issue can be a drawback not only to a single process but to the whole warehouse. The picking process, where people on foot or drivable machinery get the items needed out of VNAs (Very Narrow Aisle), is one of the most vital as it provides work for the rest of the departments and is one of the most consuming task (product handling can make up to 20% - 50% of the total operating expenses (Vonolfen et al. 2012)). Since they are a lot of different aspects of the picking process, a lot of them are subjective to modification in order to improve productivity, meet regulations or aid safety. Such alternations can’t simply be applied without being proven effective and safe, but management can only give an educated guess on the outcome of the change by using analytics that are not complex enough (Vonolfen et al. 2012).Due to those reasons a ground level test is needed where, for a specific amount of time, the process is being executed with the new change in order to gather data on the outcome and observe it. This can cause not only lower productivity and quality issues but can present a safety issue especially in relatively dangerous work environments that have people operating different industrial machinery.

How can a simulation software help solve these problems? 
Warehousing systems are complex in their nature and analytical techniques lack high level modelling of system details. On the other hand, a simulation is more convenient to model complex warehouse systems with high level of detail (Ceylan et al. 2012). A software that provides means of testing such changes by simulating them is not necessarily going to omit the need of ground level tests as it might lack the needed accuracy and situation/human factors. Instead of replacing the ground level test, the aim is to provide additional information about interactions and outcomes when a new aspect is introduced, thus aiding the decision making and reasons to conduct or not to conduct a ground level test. Usually, such live tests are conducted only out of combination of professional opinion and analytics that are falling short on complexity and detail. Such a simulation can not only let the user observe the effects on the pickers and overall productivity but can introduce situations or effects which otherwise wouldn’t be taken into consideration, thus making the management aware of other possible problems. Furthermore, all the possible changes on the layout and workforce can provide a different perspective to the management.
What follows?
	First a literature review is going to be conducted in order to explore the field, see what research has been conducted so far on the topics and compare solutions. This will help identify the correct approach and give grounds for certain decisions. Then the primary research will be conducted, which will show if the adopted solution is viable. After, project architecture is going to be represented and explained. The following will be a discussion on the achievements and also the deficiencies of the project. Then the project management, social, legal and ethical context will be looked at. Finally, a conclusion on the project is going to be stated.
Literature Review
Introduction
The reason of this literature review is to gain valuable information on the topic of warehouse simulations and consider its real-life implementation. The topic is important because without such simulation the analytical tools used to predict the outcome of certain changes in the parameters of a functioning process are not complex enough to provide sufficient information. For that reason, this review is exploring concepts that are covered or related to a multi agent simulation software.  The general scope of the review includes:
•	Warehouse management 
•	Simulating processes in a warehouse or a similar confined space
•	Critical parameters that need to be considered
•	Autonomous Agents that represent the workers
•	Path finding algorithms and related issues
•	Results analysis
The sources that are going to be used are articles that are dated in past ten years as the continuous development of computer technology and new materials handling equipment may have made any article before that irrelevant or misleading (Costantino et al. 2009). They will be reviewed independently and then discussed in their relevance to the topic of this paper, thus emphasizing the relationship of the issues to the main research problem. Aspects that are covered in more than one article will also be compared and evaluated as they may provide an inside on different viewpoints and where the disagreement comes from, thus clearing some issues. The review will be more focused on the multi-agent application and path-finding methods aspects because they are the main issues of the simulation.  Since different warehouses operate differently with different layout, methods and rules, processes similar to picking will be considered as well as they might share mutual attributes. 
Related work	
This paper (Costantino et al. 2009) focuses on a flexible simulation for warehouses that consists of evaluating analytical relations between system input parameters (like the number of workers operating industrial machines, number of shelves and their composition) and performative measure (wait time for loading and unloading operations). It states that such systems must be used for a correct system design and management in order to test all the possible combinations of the input parameters by means of the Analysis of Variance (ANOVA - is a statistical method used to test differences between two or more means).The parameters this paper is looking into are surface, shelves composition, stock capacity and it’s using a classical modelling approach for reproducing static and dynamic entities. In order to reproduce different warehouse operative scenarios, the parameters are changed and then the outcome is being observed visually in terms of operatives(workers) behaviour and statistically by observing output parameters for evaluating and monitoring the warehouse performances. The output parameters are generally consisted of time, productivity and number of operators. The evaluation approach is based on the Design of Experiments (DOE) which is a systematic method to determine the relationship between factors affecting a process and the output of that process (Sundararajan 2018) in combination with ANOVA. 
The way the process functions is with the use of DOE to determine the parameters and the range of their possible levels that can have an effect on the process. From this information, it determines how many times the simulation needs to be run to cover all of those factors and their combination of levels. Then the results of all of the simulations (with the parameters variation determined from DOE) are studied by the means of the Analysis of Variance (ANOVA) and of graphic tools in order to produce a realistic picture of the outcome.
It is important that the paper focuses more on the evaluating analytical relations than on the simulation. Even though the use of the simulation here consists of changing parameters that have a relation to the simulated process and observe the interactions and statistics, as in my concept, it has one big difference. The article simulation is focused on a bigger scope as it looks into all the possible combinations of parameters and their levels then analyses them as a cluster. Whereas our approach is more narrowed to simulating a specific combination which should be better in a robust environment, easier to test physical layout (as the article simulation doesn’t generate different layouts) and much easier to analyse. The downside of my approach would be that the combination must be generated by the user which could lead to combinations that are not explored. Both approaches undertake the same factors, but are tools designed for different needs. The DOE approach can be used in my simulation but in more complex systems it could struggle as it gets exponentially more difficult to determine connections and their influence when there are more parameters to consider.


In the article posted in ‘AIMatters’(Ma and Koenig 2017) the concept of multi-agent path finding(MAPF) and it related problems are explored on the grounds of automatization of fetching of goods by autonomous agents(robots) in order-fulfilment centres (Amazon alike warehouses where customers orders are fulfilled by the warehouse and delivering companies). The company researching the problem has been acquired by Amazon and has become Amazon Robotics which carried on researching the problem. It is stated that path finding in this case is tricky since most of the warehouse space is used for storage locations which results in narrow corridors where robots that carry inventory pods cannot pass each other. They break down the MAPF problem into smaller issues.
The robots move in a grid of cells where the cells that have robots in them are blocked. They have a start cell from which they need to reach the goal cell and the problem is to minimize the make span, that is, the number of time steps until all robots are at their goal cells. Robots are not allowed to collide, but there is an issue where a collision occurs when two robots simultaneously decide to move to the same location. The model in mind here is for the multi-agent path-finding problem, as a shortest path problem, where it takes too long to find the shortest path if it is planned collision free. The stated reason behind this is that computation requirements grow exponentially as the number of agents increase, which makes it not applicable in real life where there are a lot of workers. The suggested solution is to find the optimal path for each robot individually by ignoring the other robots, which is fast, but in case of a collision there are a couple solutions:
•	Have an algorithm that group the colliding robots together and find a solution for the group (by ignoring other robots) before the group grows too big. 
•	Have an algorithm where a collision between two robots occurs that introduces predefined restrains in an order that avoids collision and hopefully finds a solution. 

The article states that state-of-art multi-agent path finding algorithms are currently not quite able to deliver a suboptimal solution for a large number of robots in a warehouse in real-time. The tighter the space the longer the run time.
There are several aspects of the research included in this article that are, in my opinion, lacking essential information. It is taken into account that in a warehouse the robots would be working in a limited space and that path finding algorithms are used to find the optimal path for the agents individually as solving collisions is done during execution time. It is not identified how the narrow space, limits movement options and how rules of movement affect the path finding algorithm. Most path finding algorithms explore all the viable options around them and chose the most optimal, but in a confined space there could be 2-3 options in some cases from which the robot can find the optimal path quickly because of the structured mapping of the shelves. In regard to rules of movements, where the movement options of robots are constrained to certain areas or one-way roads, these constrains need to be implemented in the path finding algorithm. Otherwise, the rules can’t be taken in account or the path will need to be repaired, which isn’t optimal. It hasn’t been mentioned how would that affect the real-time implementation, it could substantially increase the computational requirements of the algorithm. 
There is a failure point in both of the solutions provided in this article that would render them inapplicable. These failure points have been mentioned, but not taken in consideration in the conclusion as it is only stated that the problem of the solutions is run time. In the first solution it is proposed that colliding robots are grouped together so they can find a solution before the group grows too big. There aren’t any precautions stated against large groups forming and no solution for such occurrence. Not only is this a potential situation where a lot of the robots end up in a deadlock(jammed) until no solution is found, but if it happens frequently, even if it’s resolved, it would affect the robots’ productivity substantially. The second solution consists of an algorithm that introduces a set of restrains to be applied when two robots collide until a solution is found or not. Again, this solution is not viable because if more than two agents are in conflict a solution would not be found, result in a collision or create a situation which can be resolved in a non-timely matter. Due to those reasons, the stated in the conclusion run time issue in real time systems is not the only problem. Finally, the existence of such Amazon branch and implications show that there is a problem that is worth solving and that such a solution is promising to deliver an answer.

The following article (Wang 2011) emphasises on the multi-agent path finding problem, the basis for which is using A* algorithm to find the optimal path in a grid map. It clearly identifies the objective of navigating agents, which move simultaneously inside a shared space, to their goal without colliding them with any static objects or dynamic objects (like other agents). It is also stated that this solution is hard to accomplish due to the exponentially growing factors when more agents are added. This article has the same objective and basis for the problem like (Ksontini et al. 2013). However, here the advantages and disadvantages of centralised and decentralised methods are explored. Centralised methods preserve the solutions completeness by planning globally and sharing information centrally (one master computer). On the other hand, the decentralised methods decompose the problem into series of smaller searches which can be handled locally or remotely with global information sharing, thus increasing the processing speed.
The researchers of this article have developed two algorithms as a solution to the problem – FAR and MAPP. The FAR algorithm is decentralised as it run A* search per agent and then repairs the plan locally and online to resolve any deadlocks by limiting movement to one blank ahead and no diagonal movements. Deadlocks occur when agents can’t proceed to their goal. The test results on FAR using this method have shown to be more efficient than previous existing systems that use the method of finding the path and then repairing it. The drawback of using FAR is that it can’t be applicable in real life due to not having a guaranteed success (86% success). The core of MAPP works with a set of rules that help reduce the deadlocks:
1.	For every consecutive triple location along the path; an alternative path connects the two ends without going through the middle
2.	A blank (unoccupied location) can be found in front of each unit in the initial state;
3.	The blocking elements are isolated from the derivative paths.
These conditions allow an agent, blocked on its path to goal, to attempt to bring a blank to its front by sliding other agents along the alternate path. In other words, this blank travelling operation enables agents to make progress on their pre-computed paths by redirecting the opposing agent.
From the testing MAPP has a 98%(of not repaired deadlocks) success rate because it can solve all the occurrences that fall in the set of rules and does it with nearly the same performance as FAR that has solved 81%. As a conclusion MAPP has proven to be applicable with a high success rate and reasonable productivity which can be further enhanced using desterilized methods.
The concept of planning a collision free path by individually finding the path for each agent and then repairing those paths on the run is the basis for all solutions reviewed so far.  What this paper is lacking is to explain how FAR and MAPP work under circumstances where more than two agents are colliding, something that is taken into account in (Ma and Koenig 2017) and identified as one of the biggest issues leading to deadlocks. The other vital problem clearly stated in(Ma and Koenig 2017) that in collision resolving with simultaneously moving agents can resolve in an agent taking a decision than can interfere with the solution of the other agent, which can lead to a loop of try-error, or both the agents may simultaneously decide to move to the same location, as part of their solution, resulting in a collision. The lack of these major issues and only the mere approach of MAPP and FAR described in this article leaves a big void in this article.
On the other hand, the use of decentralised methods to increase performance is viable solution to the exponential requirements as it shown that it can scale or perform better than centralized due to breaking the problem to smaller issues which are handled locally and online. The choice between scalability and performance is described in different examples that choose how to balance them. In order for a solution to be viable both requirements need to be met and MAPP has achieved a reasonable performance due to the decentralised approach with high scalability. This shows that the decentralised approach is a viable solution to meeting both performance and scalability.

The article (Standley 2010) explores the collision free path finding problem with multiple agents operating in a confided space with a technique called operator decomposition which reduces branching factors and independently processing subproblems. These approaches are necessary, since using only A* path finding cannot deliver a collision free execution. The researchers establish that it is hard to produce non-conflicting paths with multiple agents, even if there aren’t any obstacles. For these reasons, existing research on these problems focus on algorithms for finding good solution as often as possible rather than developing optimal and complete algorithms. The researchers look into previous methods of solutions on the problem -  LRA*(Local Repair A*) and HCA*(Hierarchical Cooperative A*) which is built as a solution to LRA*.  LRA* works on the principle of the proposed solution in (Ksontini et al. 2013). where a start-goal path is generated with A* and then repaired in order to solve deadlocks and collision in execution time by disallowing only the move that would result in a collision by taking into account the path of the other agent. The drawback of the LRA* is that it often results in cycles and deadlock. The functionality of HCA* consists of reducing the number of future re-plans by creating a reservation table for further timesteps. The algorithms have an ordering of agents and plans paths for them that aim to avoid conflict with previously computed paths by checking a reservation table. A wait move is included in the agent’s action set, to enable it to remain stationary. Even though, Cooperative solutions (like HCA*) are significantly shorter than the Repairing(like LRA*) ones, the results are suboptimal (4.3% of the instances a solution can’t be found) and there is a limitation that doesn’t allow to spend more computation time to increase solution quality. Implementing rules of travel, like one-way roads, considered but regarded as limiting because the agents will have less possible paths. The researchers also prove that A* returns optimal solutions and the problem derives from the way they are repaired for a collision free path.
The (OD)operator decomposition method presented in this paper solves one of the biggest issues in multi-agent environments, that is identified in (Ma and Koenig 2017) as well, which is agents taking simultaneous decision to occupy the same space. In standard algorithms every operation advances a state by one timestep and changes the position of each agent. The suggested method breaks down each time step to n operations where n is the number of agents. This breakdown allows the agents to perform their move consecutively which negates the possibility of two agents occupying the same space. There are issues that derive from the consecutive movement caused by the pre-move position and post-move position limiting the options of movement to other agents. Due to the consecutive nature of the solution that occurs in one broken down timestamp the pre-move positions of agents that haven’t yet queued up are taken as well their post-move positions. The moves of the agents in the queue will be limited by n (number of workers that are left in the queue). To resolve that, independence detection algorithm (ID) is proposed that groups the agents in smaller groups and tries to resolve any conflict within the group independently by figuring out if any of the conflicting agent have a path that could resolve the issue. If other agents are introduced to the conflicting group, and no resolution can be found, ID merges those agents with the group and tries to find a solution.
The test performed are in a randomly generated grid, where each position has a 20% chance to be a barrier. The results show that the standard HCA* solves 95.7% of the cases in a reasonable time per instance, whereas OD + ID solves 90.4% of the instances with substantial scalability issue caused by more instances being introduced.
The OD + ID solution adopted by the researcher has an admissible solution to one of the two big problems of multi-agent path finding (collisions and deadlocks) that were identified. The OD approach is a grantee than collisions won’t occur due to the consecutive nature of the solution, but there are two drawbacks that stand out. Firstly, OD presents more limitations to the agents (n limited space for n number of agents left in the queue) that are not looked into in depth, which could be detrimental in a more obstacle-present or rule-based space. Secondly, OD and ID are not as scalable or successful as standard approaches like HCA*. 
From the testing conducted in this article it can be stated that the Cooperative A*( like HCA*) is the most optimal method, but its’ drawback is that the number of agents, and their reservation tables, have a clear connection to the space in which they operate. If the number of agents is high and they operate in a restricted space the reservation table will be limited, thus resulting in less success rate and exponentially bigger chance of group formation. Group formations for this method could be counterproductive to both finding a solution and efficiency due to limiting the important resource of HCA* - space to work with. Another important point proven in the article is that existing research on these problems focus on algorithms for finding good solution as often as possible rather than developing optimal and complete algorithms.

	The main point of this article (Silver 2005) is to compare path finding methods. LRA* and HRC* have already been covered in (Standley 2010) and the focus is on some additional aspects: ‘Reverse Resumable’ A* (RRA*), Windowed Hierarchical Cooperative A* (WHCA*) and its comparison to LRA* and HRC*. 
The RRA* is a modified A* algorithm, introduced in this article, that finds the shortest path from the goal to the initial position. Its’ purpose is to keep the information from the search algorithm (optimal distance from N to G) for later use if needed.
The researcher identifies several issues with HRA* and LRA*. Firstly, He states that when agents reach their goal, for example in a narrow corridor, they should still be able to cooperate with other agents in order to make way. Secondly, he suggests to dynamically vary the agent order, in terms of priority, so that every agent will have the highest priority for a short period of time. Thirdly, he emphasises that complete route pathfinding is not is not efficient as it is unlikely that it will stay the same.
The solution proposed is to ‘window the search’ where agents compute only a partial root with a predefined window(w) until they reach their goal. With this approach other agents are only considered for w steps and are ignored for the remainder of the search. When the agent dose w / 2 steps the next window is computed. The window search is efficient as it takes in account the global heuristics from current state(N) to destination (G) and for every next abstract window search, until the goal is reached, the distance N-G is calculated by the subtracting N for every N reached in w steps. Further efficiency improvement comes from the fact that the next window is computed in the midpoint of the current window, so with n (number of agents) only 2*n/w searches need to be performed per turn. Finally, the RRA* search results can be reused for each consecutive window. The RRA* is initially performed for each agent from their goal position to their start position and reused every time a agent encounter takes place.
The experiment phase was conducted in a randomly generated 32x32 grid where 20% of the positions are impassable obstacles like in (Standley 2010) and none of the agents had the same start position. A failure is considered if an agent collides with another agent or exceeds 100 moves. With few agents the success rate is 100% but when more are introduced the rate drops to 80%. It is stated that Local Repair A* may be an adequate solution for simple environments with few bottlenecks and few agents. With more difficult environments, Local Repair A* is inadequate and is significantly outperformed by Cooperative A* algorithms. The path length per number agents test shows that HCA* has the best performance (path length of 27 per 100 agents) with no exponential growth and is shortly followed by WHCA* that has a has a 32 path length per 100 agents and it growing faster than HCA*. Both WHCA* and HCA* have a nearly linear success rate of 98%. The LRA* method has the worst performance (path length 44 by  a 100 agents with big dependency on the success rate from the number of agents – on 50 agents 94% and on 100 agents 80%. 
The three issues with HRA* and LRA* stated by the article are valid, but they could have been looked into to greater extend. Regarding the first issue where the agent reaches its goal they stop cooperating with other agents to make way is reasonable, but in what implementation does an agent just go to location and doesn’t move again. He is either going to have another goal state to reach, relocate to a deployment sector or have as a goal to give way to others. Otherwise, it would be an incorrect design. Dynamic agent priority is a concept that makes it easier to determine which agent should give way, but it is not very clear how priority is going to work when more than two agents collide as the one with priority might need to move last in order to solve the deadlock. The last issue is related to planning the whole path from the start and that is less efficient than their proposed solution ‘window search’. In theory, with multiple agents, the initial plan will most certainly be altered, but how much would those small alternations that occur, due to going around other agents, deviate from the main path? The WHCA* ‘window search’ uses RRA* in order not to deviate from the shortest path. How would the actual path be different with window search since it’s aiming at the most optimal path, which is already predefined in the other methods before execution. An optimal path is an optimal path, regardless of its broken down to smaller searches or a full path search. Window search does take into account only the agents within the window and ignore the rest, but so do the rest of the methods in one way or another without having to compute smaller sections.

Conclusion
In order to have a correct system design, in a simulation of this type, all attributes that can have influence over the simulated process need to be included. Furthermore, using autonomous agents that operate in a grid is shown to be a valid way of building a simulation. The researchers also prove that A* returns optimal solutions and the problem derives from the way a collision free path is generated. From Amazon Logistics looking into the issues of multi-agent systems (Ma and Koenig 2017) it can be deduced that the problem is real and worth solving. It can also be stated that most of the warehouse space is used for storage locations which results in narrow corridors where cannot pass each other.
The state-of-art multi-agent path finding algorithms are currently not quite able to deliver a suboptimal solution for a large number of agents operating in an obstacle-present environment. By observing the attempts of other researches to create a multi-agent simulation one can identify two major issues deriving from agent interaction that they have to solve (deadlocks and collisions). Planning collision free paths pre-execution is not an option as it is established that it is hard to produce non-conflicting paths with multiple agents even without obstacles (Vonolfen et al. 2012). Other elements like exponentially growing factors when multiple agents are introduced, and the narrow nature of a warehouse also makes it inapplicable. Due those reasons researches choose to process the optimal path for each agent, by ignoring the rest, and use different methods in case if a potential collision. The use of A* path-finding algorithm delivers an optimal solution to finding agents paths individually. There is a multitude of different methods that attempt to solve collisions and deadlocks with the post-execution approaches. Breaking them into categories will help analyse them better.
•	Repair method (LRA*, MAPP, FAR)
•	Decomposition method (OD + ID)
•	Cooperative method (HCA*, WHCA*)
The Repair methods have two things in common, they find the optimal path before execution and ‘repair’ paths in order to resolve conflicts when needed.  This method is a viable solution for smaller number of agents, yet its’ performance time grows and the success rate drop significantly when a larger number of agents are present.
The Decomposition method consists of breaking down every timesteps to n (number of workers) so that the agents can move consecutively in one timestep. Here, one of the problems identified earlier(collision) is solved, but at the cost of additional restrictions. Due to the consecutive nature of the solution the following limitation is present: (n limited space for n number of agents left to move in the timestep). In addition, OD + ID are not as scalable as Cooperative approaches and may not perform well in a more obstacle-present environment like a warehouse. 
The Cooperative method works by reducing the number of future re-plans by creating a reservation table for further timesteps and in the case of WHCA* it breaks down the path finding to smaller paths(windows). It has a wait functionality, so it can omit the need of conflict resolution. Cooperative methods have a high success rate and the time of task doesn’t grow exponentially when multiple agents are introduced. Proven to be shorter and more efficient than LRA* repair method as it tries to avoid conflicts beforehand, whereas the repair method resolves conflicts only when they are imminent.
	Due to the performance, success rate, scalability and introducing minimal restrictions of the Cooperative method, compared to the Repair and Decomposition methods, it can be concluded that it is a correct and efficient approach to solving interaction problems in multi-agent systems.

Furthermore, the use of decentralised methods to increase performance is viable solution to exponential requirements and it can scale or perform better than centralized due to breaking the problem to smaller issues which are handled locally and online. A pre-modelling analytics like Design of Experiments (DOE) can be used as a prerequisite to the simulation in order to identify possible scenarios and scope of attributes. Issues with DOE can arise if there are too many attributes because it’s runtime increases exponentially. Finally, in this field of study, there is gap where simulations are built with randomly generated obstacles and it is not taken into account how different amounts of obstacles or obstacle patterns influence the different methods.









Primary research method and evaluation
The primary research consists of quantitative and qualitive research. The quantitative research is testing the warehouse simulation software where the time for which a specific number of units is picked, and the number of agent interactions are taken into account to determine if the simulation can produce adequate results. On the other hand, the qualitive research is conducting interview on warehouse managers or related positions to determine if the developed solution is viable and what further improvements it needs.

Interview Method (Qualitive Research)
Method:
The method consists of interviewing people with management related position in the warehouse industry to explore their perspectives on the developed solution. Due to the very narrowed range of possible participants, six interviews were conducted. The format of the interview is structured as it is composed of a series of pre-determined questions that all interviewees answer in the same order. First, all the questions and their answers are going to be review in a consecutive matter and then a conclusion is going to be drawn. Participant information sheet and Consent form can be found in Appendix 4 and Appendix 5.

 Research:
Question 1:
Do you think such a system may provide valuable information on the following aspects:
- How changes in the layout of the warehouse can affect the process?
- How changes in rules of work/interaction can affect the process?
The participants state that a change to the collection of service points (I.e. collection/drop-off/ control stations etc.) will undoubtedly modulate the overall efficiency of the system. Although, layout changes might increase efficiency by a certain amount of saved time, it would cost lots of money to change the layout of warehouse. Additionally, the layout of the warehouse has another aspect to it as current warehouses layout is created by people who research the ergonomics, risk and threats of certain elements. So, the simulation can provide performance measures, but the change is going to be dictated by other major aspects as well. On the other hand, the simulation can provide invaluable means of alterations in the special configuration of the warehouse or process design without risking the integrity of the established process, as potential disruption constitutes the main barrier to more experimental approaches being explored.
The participants identify that the most time-consuming aspect of the picking process is getting to the locations (i.e. drop areas and collection zones) and that efficiency is dictated simply by units picked divided by unit of time. So, gaining more information about the rules effect, in principle, has great potential. It is also stated that the successful adoption of the system will be highly dependent upon the ease of rule creation, thus needs to be the focus of developers. Finally, the possible changes that are shown in a simulation can certainly give another perspective for the management.


Question 2: 
Can you think of any other elements of the layout that can have an impact and have not been mentioned by the researcher?

The participants imply that in this state of possible changes it would be better to stick to current warehouse layout options because it is fully resistant to safety risks and is efficient enough for current workflow and worker amount. However, most of the Warehouses are still using trolleys with totes for picking, so the simulation might not be applicable. The layout might be on a single, flat surface but also it can be a so called “pick tower”. Pick towers are multiple floors with the same layout on top of each other. This adds lifts which need to be considered. Also, a two-way movement within the VNA (Very Narrow Aisle) would be more efficient idea but that might be a slight safety risk for pickers because two order pickers would be moving in opposite directions. Another missing aspect is that not only pickers operate in the VNAs as there are other workers that need to load items in the shelves or perform inventory check as they can greatly influence the process. It should also be recognised that there are two discrete elements which synergistically cooperate toward the productivity of the order picking process. The simulation pays rightful attention to the physical constraints of the individual and of the group mechanics, but currently only offers elementary parameters of the virtual pick system itself. The most obvious oversight is the impact of time because when deadlines, for orders to go out of the warehouse, approach the system exchanges efficiency for priority of the items that need to be picked immediately. This will have major implications on the dynamics of pickers movements; a very complex but internal part of any viable simulator.

Question 3:
Can you think of any other rules of interaction that can have an impact and have not been mentioned by the researcher?

It was identified that non-productive traffic was not taken into consideration as there are other workers that load inventory in the picking locations. As the primary concern of a warehouse operation such as this is safety the addition of more traffic and the subsequent congestion produced by service points should be configured to produce a risk index. This index should describe statistically the increased potential of vehicle collision, and the subsequent productivity implications thereof. An important aspect of picking process that not in the simulation is pointed out, where sometimes the pickers are called back by the management in order to deliver work for different departments. This can be an important factor during busy periods because calling everyone at the same time is losing a lot of time due to congestion. For that reason, the pickers are called in groups, which size is deduced from the drop zones size and their distance from the drop zone. If this simulation is to present the process fully, this implantation is needed.

Question 4:
Do you think that, with the current state of the visuals, the effects of the above mentioned possible changes can be observable?

All the participants agree that the mentioned ideas are more that possible to be observed and tested in this state, unless there are multiple floors available. The problem is that the movements of the pickers in the visuals is uniform and immaculate and it’s not the reality of human operated machine. A suggested solution is coding several diverse movements of the vehicles and then assigning a random function to their execution to more closely emulate a real-world environment. As mentioned before, an accident index will increase the realism and value of such a program.

Question 5:
In your opinion, what further improvements can be made to expand functionality?

From the interviews, the following improvements were suggested:
•	Speeds of order pickers inside and outside the VNAs
•	No movement limitations if you are too close to racking
•	Two-way road in VNA
•	Configure app to work with both PUP drivers and foot pickers.
•	The program need to run all OS
•	Simulation files/results small enough to email/share
•	User friendly GUI that someone with zero coding or even computer literacy can use

Conclusion 
The result from the interviews shows that managers in the industry agree on a lot of the decisions and reasoning taken in building software. It is agreed that the layout and rules are the two main aspects that influence the picking process. Having a safe mean of observing the result of altering those aspects will not only provide valuable information but can give the management a new perspective and even a way of testing more farfetched ideas. Regarding the layout it was said that simulation pays rightful attention to the physical constraints of the individual and of the group mechanics. As to the rules of interaction between static and dynamic objects, no other where proposed apart from taking more time to get in the VNA(Very Narrow Aisle) as a safety regulation. The way efficiency is measured in the simulation research method matches the approach of measuring efficiency that one of the participant managers stated. It is also identified that the most consuming task in the picking process is getting to the locations of picking items and dropping them. One of the questions that had to be answered, in order to know if the simulation approach is viable, is if the process is observable. All the participants agreed that in the current state the process is well observable, but it is lacking the realistic movement as it is too uniform at the moment. From observing the answers, that vertical level didn’t affect movement and knowing that vertical movement is implement, one can deduce that the visuals need to be advanced in order to depict it. The need of risk index that indicates the more dangerous situations occurring was also raised up, but at the point of conducting the interview the agent interaction variable was not present. The statistically observable factors identified in this research consist of time, picks, congestion and risk index.
Although, there are a lot of suggestions on expanding functionality, which were not relevant as this is a proof of concept, some need to be taken into account because they could be vital for a full implementation of a warehouse simulation. The researched showed that the successful adoption of such a system will be highly reliable on a user-friendly UI that allows easily comprehensive editing of rules and layout due to the complexity of the process. An additional factor which is not present in the simulation was mentioned in the interviews. There are not only pickers that work in the VNAs, but there are other workers that store items as well. If this is a factor that need to be taken into account when testing rules and layout, void workers that wonder in the VNAs could be introduced. Other requirements included the result and simulation files to be small enough to send over email and the simulation being runnable on all OS. 

Simulation run method (Quantitative Research)
Method:
Because the simulations take a long time to run (more than an hour), due to the visualisation aspect that needs to be observable, the conventional way of performing a large quantity of simulations and then analyse them is not applicable. Instead, a small amount of simulations is performed and then analysed to deduce if they depict the process accurately. The simulation research method purpose is to test whether the simulation software developed meets its design objective.  In order to establish that, the simulation must be able to perform a successful base run on a given number of orders that is observable and provides adequate statistical information about how many items were picked in what time. In addition to that, another simulation is going to be ran in parallel with the same collection of orders, but with a critical parameter change (altered simulation) that is clearly counterproductive for the workers, in order to establish if the simulation will produce accurately lower productivity than the base run. Number of interactions made between the agents is a variable that is going to be taken in consideration when analysing the two simulations as well. In addition, as a variable that keeps track of more complex interactions, the occurrences of agents ignoring the opposing conflicting agent (the workaround mentioned above) will be taken in consideration as well. As this occurrence means a complex/hard to resolve interaction, it is going to be used as a ‘risk index’. 
	In order to be sure that the parameter that is going to be changed is going to have a negative effect, for the purpose of validation, the middle drop zone (Figure 1 present in Project Architecture) is going to be removed. The effect from that is clearly going to make around 1/3 of the agents take a longer path to a more distant drop zone in order to drop-off their totes. As the estimate average picks per worker are 50 (1000(picks)/20(workers)) and the most number of items the worker can carry is 25 (5(totes)*5(items)), the workers that depend on the removed drop zone will have to take two trips to a distant drop zone where more chance of interaction with other agents can occur. To solidify the results, a second pair of simulations are going to be ran. The only difference to the prior pair is that the carry capacity of the workers is going to be lowered to 15. This will help the difference stand out and will show how the effect of it corresponds to the times a worker drops his load. This effect must be noticeable when two simulations from one pair are compared. The rest of the parameter remain the same, as follows:

The parameters in use for the base simulation:
•	Number of workers: 20
•	Sector locks: 8
•	Vertical level rule:  Can’t drive forward above “K” level
•	Maximum empty tone number: 12
•	Maximum full totes: 5
•	Maximum volume per tote: 5
•	Time spend in dropping area: 10s
•	The same set of orders (1000)
•	Same rules of transport

Results:
In the first pair of simulations 20 workers whit a carry capacity of 25 are tasked to perform 1000 picks, on the same set of generated work, with 2 and 3 drop zones respectfully. The simulation with 3 drop zones serves as a base for the test so that we can observe the difference upon comparing it with the (altered) second simulation that has 2 drop zones. Removing a drop zone was chosen as the dictating factor for the simulations because it can be easily deduced that it will have a negative effect on distance travelled and agent interaction on a portion of the agents. The base simulation finished its task for 4751 seconds with 511 interactions between agents, whereas the altered one finished with 4985 seconds with 594 interactions. The base and altered simulation had a risk index of 25 and 33. To sum it up, the time it took for the altered simulation to perform the same task was 4.9% higher and it had 16.2% higher agent interactions. 
	The second pair of simulations are identical to the first pair apart from the carrying capacity of the agents, which is reduced to 15. This will help, solidify the results and show how the effect of it corresponds to the times a worker drops his load. The base simulation took 4980 second and had 660 agent interactions, whereas the altered simulation took 5541 seconds with 721 agent interactions. The base and altered simulation had a risk index of 33 and 64.  To sum up, the time it took for the altered simulation to perform the same task was 11.2% higher and it had 9.2% higher agent interactions. All the results can be observed in Figure 0.


Figure 0(Simulation results)
 

With a drop zone removed in the altered simulation, the agents relying on it need to take a longer path to the other drop zones, thus creating more traffic and interactions with other agents. Form both simulation pairs comparisons it can be concluded that the simulation depicted the predicted increase of time and interaction when a drop zone is removed. 
It is expected when the pickers need to drop-off more frequently the time for the whole process is going to take longer due to the additional movement. When comparing the two pairs respectfully it can be seen that the simulation adequately shows increased time for the process where a more frequent drop-off is occurring (226/556 seconds more). 
In theory, more frequent dropping off takes more time but lowers the congestion and risk when dropping off because the more frequent the action the more spread it is throughout the process. Whereas less frequent drop-off will create clusters of workers that need to drop-off in the same time, as mentioned by one of the participants in the interviews. This effect can be observed when the two pairs of simulations are compared. In the more clustered drop-off, in the first pair, the effect of using one less drop zone results in 16.2% more agent interaction. Whereas, in the case more evenly spread drop-off in the second pair, using one less drop zone results in 9.2% higher agent interaction.
The more frequent drop-off should result in more time spend by the workers outside of the VNAs and more clustering around the other drop zones, thus creating more dangerous situation. The effect of this can be observed when the risk indexes of the two simulations with one less drop zone are compared.
The effect can be clearly seen as the more frequent drop-off resulted in a risk index of 64, whereas the less frequent resulted in 33.

Conclusion:
The results from the simulation show that not only the major statistical factors (time, picks, congestion and risk index), that are identified in the interview method, provide adequate information dictated from the scenarios, but they can also be used to correctly identify the predicted outcomes. From those observations it can be concluded that the statistical factors and derivative effects are adequate and observable.







Project Architecture 
Visualisation
The multi-agent warehouse simulation is written in Python. For the visualisation aspect the Python module pygame is utilised where a free tile set is used to depict the warehouse layout (1260x324 pixels). (Figure 1).
•	Workers are deployed from (0) one by one. 
•	Drop zones, where the pickers drop of their totes, are the orange spaces on the top (1)
•	Shelves are the dark grey vertical lines in the middle (2).
•	Roads, where the workers go in to pick items from the shelves, are situated between the shelves. (Very Narrow Aisle) VNAs
Due to the rules of transport between the shelves, a one-way system is required and represented by green for entry and red for exit. The workers must follow the one-way system in the VNAs and are not allowed to go backwards.
Figure 1(Warehouse layout)







Limitations of the visualisation
Due to hardware limitation, wide nature of the layout and the multiple tiles that need to be depicted a tile-size of 9x9 pixels was used. Warehouse simulations could require a substantially bigger layout. From the above mentioned it can be deduced that if the simulation is to be fully viewed by the user, a hardware limitation is present. A concept for improving the visual aspect was created, but not implemented because of the tile size limitation (Figure 2).
Figure 2(Tile set concept)



If individual elements have to be drawn the whole map must be redrawn. Worker threads can’t draw them-selves on the map as they overdraw the prior ones. As a solution, a controller thread was made in order to gather all the agents’ positions and draw them in one go every timestep (1 second). Using the module pygame to create the visualisation might not be an optimal solution. An issue is present with the simulation where if the pygame screen is interacted with or minimised it would break. A solution was not found, research indicated that pygame isn’t very thread friendly.

Path-finding and implemented rules
The path finding algorithm in use is A* as it is considered the optimal solution for finding the shortest path from a start to goal point in a 2D grid. This pathfinding algorithm uses heuristics (hscore) in order to determine which locations to explore in regard to their goal proximity until the goal is reached. In the warehouse simulation workers have to abide by the one-way VANs. Because A* explores the closest to the goal unexplored locations, it has to be modified if rules of travel are to be implemented. In order to be able to apply these restrictions the state of the agents needed to be kept accounted for. The way A* is able to follow the rules is by knowing if the agent is in a VNA and where the exit is. Given that the worker is not supposed to go towards the entry the algorithm explores to and beyond the exit. 
A problem was encountered because when the algorithm explores one entry it doesn’t have to follow the rules in order to get out. In the case where the entry is a correct way as the agent needs to pass through in order to get to the goal, the algorithm needs to follow the rules. The solution was to keep track of the last position explored, thus updating the status of being in a specific entry. If the algorithm wants to go through an exit, even though it was exploring another entry beforehand, it has to have the location before the exit explored in order to be registered present in between those exact shelves so it would be able to go out.

Elements of the picking process that are a subjective to change.
The physical layout of the warehouse:
•	Overall space schema (chambers and their size).
•	Number of shelves, their height and composition of space for stock.
•	Areas that are/aren’t driver accessible.
•	Drop-off of zones for pickers (size, composition, number, spacing between zones).
The rules the pickers need to abide by:
•	Distance between operating vehicles.
•	Maximum height when moving forward when in racking.
•	Quantity of empty/full totes allowed to be carried.
•	One-way rule when entering VNAs.
•	Give way to other pickers to pass before exiting the racking.
•	One-way roads outside the racking.
•	Maximum speed allowed in different areas.
•	Required distance for approach to enter/exit shelves
•	Locket in to work in specific sectors 
Picker related parameters:
•	Number of pickers
•	Base time in which the item is picked once the worker is in the location
•	Range for additional pick time that replicates the human factor

Threads, agent interactions and related processes
The workers share mutual resources and since they are represented by thread, a bottleneck needed to be introduced in order to properly operate with those resources. Whenever an agent accesses resources or gives feedback through printing it locks the variables in use and the printing function. 
Each threaded worker has its own instance in a class that keeps its internal state which is represented by the following:
•	Drawing function for pygame
•	Current position (get/change)
•	Lock sector (get/change)
•	In/out shelves state (get/change)
•	All tote parameters – number of empty totes, full totes, volume current tote (get/change)
A standard termination process is implemented to make sure that when the main thread dies, all derivative threads are terminated. The workers are represented by autonomous agents (each running on s separate thread) that use A* path-finding algorithm individually to find the optimal path from their current location to their goal by going around the static objects and ignoring the rest of the workers. The main problem of this kinds of interaction, as identified in the literature review, is that when multiple agents are introduced the path is not guaranteed to be resolved even by the state-of-art algorithms build so far. Due to the narrow nature of the warehouse environment, the options for movement for multiple agents are limited, which drops the success rate of such algorithms substantially. Essentially, the simulation needs to represent the workers interaction adequately in order to reproduce accurate results. Since in real life such conflicts are resolved easily, overextended tries to properly solve and depict the conflict between multiple agents can result in a deadlock or over-exaggeration of the interaction, which is not acceptable for the purpose of the simulation.
In case of collision-prone interaction, a variation of the heuristic cooperative method is used where the agents take into account the next two positions in their path (a private reservation table). If this interaction occurs in the VNAs, the agent must wait until its path is free, due to not being able to go back in a one-way road. Otherwise, it tries to resolve the conflict in two windows consisted of 2 and 3 timesteps (ts) respectfully. In the first window, if there is a dynamic obstacle present in the next two positions of the path, the agent waits for 2 (ts) in hope that the path will be cleared. If the agent reaches the second window and there is still an obstacle, it presumes that the obstacle won’t move in a timely-matter, thus tries to go around by shifting its path around the obstacle. If it doesn’t manage to find a solution to get on course of the optimal path within the second window (3ts) it ignores the obstacle and caries on its path until it doesn’t encounter another obstacle. This solution is not optimal as the agent can go over the obstacle in order to resolve a deadlock and prevent group formation, which is unacceptable for most of the simulations purposes. The reason this approach is adopted is that for the purpose of this simulation the worker interaction must be presented adequately in order to produce accurate results. In a real-life interaction, worker (1) will observe worker (2) in order to gather information on his path. Then, depending on that information, worker (1) will wait for his path to be clear or go around worker (2) in an efficient way. If this interaction is to take place in a simulation, there is a chance that worker (1) won’t find and optimal solution. This can result in a deadlock or take too much time, which can result in an exaggerated interaction that could lead to group formation, thus making an even bigger problem. Such hiccups will affect the simulation results by overexaggerating the traffic aspect or lead to a group formation that makes the problem exponentially worse. It has to be stated that this isn’t a solution to the particular problem, but rather a workaround (for a global problem) for the purpose of proving the concept. In order to track the occurrence of this workaround, information about how many interactions occurred and how many were solved by ignoring the problem is being tracked and displayed in the end of the simulation.
An example, from a simulation, of how the above-mentioned solution works can be observed in Figures (3-12). In the first figures in can be observed how the two agents on the right are in conflict as they are moving against each other, thus occupying the opposite agent reservation table. First, they stop for their first window, where they wait for their path to be cleared. In Figure (5) in can be seen how one of the agents proceeds to his second window and moves aside as an attempt to bring an unoccupied space in front of him, which allows the opposing agent to proceed forward and clear the path (Figure 5-8). When the path is cleared the other agent finds a way to its optimal path and returns to it (Figure 9). As this happens the approaching agent from the left get in conflict with one of the previous agents (Figures 8-9). The left agent gets into his first window and waits for it’s path to be cleared in order to avoid conflict, while the right agent path is not conflicted with because he needs to get in the VNA and no obstacle stands in its way (Figures 9-11). When the right enters the VNA, the left has its path cleared and doesn’t proceed to his second window as he successfully managed to avoid the conflict and carry on his path (Figures 10-12).
                                               Figure 3-12(Example agent interaction)















Approaches considered as a solution to the above-mentioned problem

1.	Thread communication for a collaborative solution (Thread Condition Options)

Thread restriction was implemented as an attempted solution by creating a condition block on the reservation list in case of imminent collision. When this happens the first agent that creates a condition has the right over its reservation table and any other agent that attempt to pass it end up in a block. Once the agent that has created the condition is back on its optimal path, it releases the condition allowing the other agents to pass. This solution worked perfectly with two agents as the deadlock and collision problems where omitted and the interaction was optimal. When more agents were introduced, large group started forming. The reason behind the large group formation was that sometimes the agent that set the condition encountered a dynamic obstacle before reaching its optimal path. That agent either gets blocked by a condition or creates another condition in order to get back on track, thus leaving a trail of blocked workers that potentially block more. A version where agents released previous conditions before creating new ones was also tested, which created another set of problems. Group formation occurred less frequently, but some agents that had to create several conditions to get to their optimal path ended up deviating too much. When a heuristic method (try moving towards the optimal path) was adopted to make sure this didn’t happen, some agents kept loitering around as they couldn’t pass. This generated more traffic and more interactions, thus resulting in an exponential group formation. This occurred because the agents left behind from the previous constrains and the ones that are in front with active constrains create a maze that the agent needs to pass in order to progress towards its optimal path.
2.	Dynamic priority allocation

It was attempted to dynamically allocate a priority to each agent overtime in order to replicate collaboration. In some situations, agents with higher priority had limited option of movement, where the correct solution would be for the opposing agent to have priority. The priority was neglected when a high priority involved agent was going out a VNA because otherwise it would result in a deadlock. When the interaction involved two agents, this wasn’t an issue, but in the case where more agents where involved and the agent with the highest priority was limited the outcome was slow and prone to group formation. 

 
Workers deployment

For the workers deployment a thread synchronization process is used where all the threads get blocked by a condition, until they are notified, by another worker, to check if the condition is met. The solution was built from a simplified version from Python threading documentation to a block/wait(condition) process that deploys the workers consecutively. This is the most efficient way as no unneeded computation takes place due to the workers notifying each other when the right time to go is.
Expanded solution:
# Consume one item
cv.acquire()
while not an_item_is_available():
    cv.wait()
get_an_available_item()
cv.notifyAll()
cv.release()



Work and map generation
The agents(pickers) ‘work’ is generated per sector lock. Each agent is locked to a sector and only takes ‘work’ from that sector. The ‘work’ is broken down to batches of items, like in a real warehouse. Each item in a batch has a vertical and horizontal location. When those batches are generated they are allocated to queues that correspond to the specific sector. The sectors, number of batches and their volume can be manipulated. There is an option to use the last generated work, as for the purpose of the simulation a base (how the simulation performs without the changes) has to be established in order to be compared to the simulation run with the change implemented.
A converter function and a map converter are implemented as well because the simulation has two states the coordinates could be in. Because the A* algorithm works with a 2D list (of 1ns and 0s) and on the other hand, pygame works with pixels.
The simulation has a function that defines the different static objects of the layout. At its current state the function always builds the same layout as its written to do, but its presence is mandatory if the simulation is going to have UI where the user can alter the static objects.


Picking at the goal location
The picking of an item in the goal position needs to replicate a real-life situation. When the goal position is reached the picker needs to reach the vertical level of the item in order to pick it and go back down in order to be able move forward. To determine how long the agent should stay in the location of the item several conditions are taken in account. 
•	The maximum allowed vertical level that the agent can drive on.
•	The current vertical level of the agent.
•	The amount of locations it traveled between the specific shelves to get to the location.
•	The base time to pick an item.
•	A randomly generated additional time for picking.
	
First, the actual picking, when the location is reached, consists of a customisable base time for performing the task and random time variation that replicates the human factor. The workers can move vertically only in VNAs. Vertical and horizontal movement at the same time is possible, as long as they don’t go over the allowed vertical level for horizontal movement. Instead of updating both vertical and horizontal levels and have an algorithm that decides the optimal vertical movement, a shorter solution is introduced. The vertical level of the pick is taken in account upon reaching its horizontal level. Then the optimal height the agent could have reached by that point is deduced by taking in account the previous vertical state and how many positions the worker has moved in the VNA before the goal point. From that point, the moves between the start and goal of the vertical movement are calculated and added to the timesteps, together with the picking, human factor and going down to the allowed vertical level for horizontal movement.

Main functions breakdown

Worker function:
•	Keeps track of tote state.
•	Movement to goal.
•	Conflict resolution.
•	Bottleneck synchronization functionality for agent deployment.
Worker thread:
•	Main process handler for each thread that allocates him work.
•	Initializer function that creates the threads.
•	Locks agents in a sector.
•	Send them to do work until there isn’t any more work to do.
•	Drop off totes and get to spawn position.
Main(_main_):
•	Initialize pygame.
•	Set variables regarding rules and number of workers and number of batches and items in each sector.
•	Setting up the queues for the different sectors.
•	Filling the queues with work.
•	Locking the workers in sectors.
•	Creating the workers thread and the controller thread.
•	Initialing the process


Discussion
The major elements of the developed software are the autonomous agents represented by threads, collision free path finding, rules implementation, layout generation and visualisation. The development took more time than anticipated due to the slow simulation time and need to manually generate scenarios to test. Since the agents are represented by threads that use a lot of mutual resources and interact with each other, their presented a big challenge. In order to make it possible for them to work together locks where needed so they can properly operate with mutual resources. Furthermore, the deployment of the agents was problematic and as a solution a thread synchronisation process was adopted, where the spawning agent notifies the next agent when he can come out. The other major issue that most of the literature review focused on was the collision-free path finding of the autonomous agents. This has been a topic for a long time and numerous approaches have been tested, but none of them have a 100% success rate when multiple agents are introduced in more obstacle-present environment. A lot of different types approaches where reviewed and considered and as a result the Cooperative method was deduced to be the most effective. The lack of guarantee for the path finding turned out to be a serious problem as no simulations could withstand a full run because some of the agents couldn’t find a path and either broke or passed to the next order. As a workaround the agents where let to ignore each other if they couldn’t find a solution for a period defined by their cooperative method (window/reservation table). Luckily, this didn’t present a vital problem to the simulation design objective as the process of trying to resolve the problem simulates a real situation where workers would have found a solution, thus keeps the integrity and realistic nature of the simulation. The rules implementation was harder than anticipated as well due to the pre-execution path generation approach. Using this approach meant integrating the rules in the A* path finding algorithm, which was tedious to test due to the simulation speed and the need of manual situation generation. The layout generation and visualisation where successful, as they where deemed easily observable in the interviews, but are the least developed aspects of the software due to not being as critical as the rest.
There are a lot of aspects that could have been implemented or further improved but weren’t due to the short period of time and complexity of the project. The most important one is finding a better solution to the workaround of agent interactions. Even though it was a viable solution, as it replicates the interaction, it is not optimal. There are some pointless movements that the agents perform but really don’t affect the simulation apart from observing the agents perform them. An example of that is when agents move in a line and the first agent in the line has to wait for 2 seconds so that it can progress due to an obstacle. The agents in the back of the line start moving around the queue only to get back to their original path in their next move as the agents in front start moving again. As to the visualisation, the concept tile-set (Figure 2) could have been implemented easily if the hardware limitation was not present. In addition, the agents’ vertical movement visualisation was in development but couldn’t be completed due to more important tasks being present. A python library (matplotlib) that produces graphs was explore as an additional way of presenting simulation results but was not compatible due to ‘platform independency’.

Project Management
Project management, meetings 

As the project progressed, numerous meetings with the supervisor took place in order to make sure the project was going in the right direction. All the meetings with the supervisor, discussed topics and progress are documented and attached in the appendix (Appendix 3.). Advice was often sought from the supervisor by the means of emails in between the meetings to address single questions. The more major discussion where held in the meetings where the options where weighted and considered. The planned duration of the project was initially dragging behind schedule with a week but caught back on track when the exploration of the simulation aspects took less time than expected. The time span of the project milestones can be observed in the project planner (Appendix 2.).
Because the topics of simulation, autonomous agents, threading, and visualisation where were an unfamiliar ground, it was decided to build a very basic version of the simulation before doing the literature review. The reason behind it was to explore the scope of those topics and familiarise with them before diving into deep research. This helped avoiding the risk of committing to an idea based on research that couldn’t be implemented. Furthermore, this aided the better comprehension and critical analysis of the literature review as the topic where previously explored.
	The interviews had to be conducted remotely because the participant needed to be a part of management in a warehouse and the available ones are living in different cities out of Coventry. Due to the narrow range of people only six people participated, but they provided more than sufficient information. The questions for the interview where build with the help and consultation of the Academic Writing Centre in order to make sure that the interviews will deliver valuable information.
	The simulation was initially supposed to run faster, but during development the inability to observe the process became clear when more speed was introduced. The conventional way of simulating is to run multiple simulations and then analyse the outcome but given that the simulations needed to be observable and to perform a longer task, so certain aspects can be identified, such approach was not applicable due to mere execution time (over an hour). Instead, a small amount of simulations was performed and then analysed to deduce if they depict the process accurately.

Project presentation

A presentation that showed current progress and down the road plans took place in front of the supervisor (Appendix 6). Three major points where discussed: Multi-agent system, generating work and map visualisation. At that point, the threaded workers were implemented with A* path finding algorithm that navigates them to their goal in their locked sector. A controller thread that tracks the agents state and draws them on the grid was also implemented. This was the base state from which the further research would show the correct approach for managing the agents. The considered and presented approach was to implement the collision free path finding by implementing consecutive movement which would also help the agents to use mutual resources without overlapping. Later on, research in the literature review showed that this approach wasn’t optimal. The cooperative collision-avoid method was deemed better and locks where introduced for mutual resources. Additionally, an internal-clock was presented as a way of tracking the workers progression but deemed unnecessary by the feedback.  An implementation of global timesteps was pointed out by the supervisor as a more optimal and easily adaptable solution. Those timesteps were adopted and later integrated in the windows of the cooperative method. A major discussed aspect was the optimality of the A* path finding algorithm in the limited options of movement in the warehouse layout. It wasn’t concluded if A* was the optimal approach, but it was considered applicable. This showed that further research was needed, which later on showed that A* was the optimal solution for path finding without the extend of the collision-free aspect. Regarding the work that the agents perform, the current state was generating picks only on ground level. The next step was to implement vertical level to the picks and introduce a human factor by randomizing time for the picking of the item. The feedback on this approach showed that it was better to have a base-time for the process and then add additional time from a predefined range. In terms of map visualisation, the current layout build was presented and as further work a concept of a custom tile-set was shown. The feedback on the visualisation was to not focus a lot on it in case of short time. The concept ended up being developed into a tile-set, but the hardware limitation didn’t allow the tile-set to be in the needed size of 9x9 pixels. An option for finding more participants for the interview was given from the supervisor, but it didn’t work as no response was give to the request for interview. Finally, other major plans where stated to implement functionality for workers breaks, gather information about the full simulation run and narrow down the productivity to a realistic productivity rate. The supervisors pointed out that the simulation should have the ability to store previously generated work as it would serve for a base for all the simulations when a change is tested. This was taken into account and an option to use the previously generated work and store in was implemented. As the project expanded, worker breaks and narrowing down the productivity rate to realistic ones was deemed not needed for the purpose of the simulation.

Social, legal and ethical context

	An ethical issue could be that people analysing the factors could lose their jobs as the simulation would be producing analysis. From the interviews, it is known that people analysing the factors take into consideration a lot more aspects, and that a decision can be aided by the simulation, but there are other factors that will dictate it. Give those factors it can be deduced that the simulation will not replace a work position but rather contribute to it.
	A legal issue could derive from conducting the interviews with the managers as they could unintentionally leak company private information. This could lead to contract breach on the managers side and lawsuits against them. One potential participant declined participating in the interview for these reasons. As a measure for preventing such occurrence, specifics that posse risk of breach of contract were left out of the project and the collected data will be destroyed after this paper is graded.




	


Conclusion

This paper explores the idea of a warehouse simulation software that provides means of simulating the picking process. The viability of the simulation is dictated by its ability to perform a full run that adequately depicts the picking process statistically and visually. The conducted research shows that not only the statistical factors, identified in the interviews, provide adequate information dictated from the scenarios, but they can also be used to correctly identify the predicted outcomes. It is proven that the nature of the visuals is sufficient enough to observe the picking process and depict the different situations that occur. Multiple collision avoiding methods (LRA*, MAPP, FAR, OD + ID, HCA*, WHCA*) were considered, analysed and compared in order to determine the optimal approach.  The implementation of the Cooperative path finding method proved to be an efficient way of avoiding collision because it introduces the ability of the agents to avoid conflict during execution time by waiting for the obstacle to clear their path. Furthermore, the picking process has been explored in depth and its critical points, different scenarios, efficiency estimation and scope of possible alternations have been identified.
	Ways to improve and aid the use of simulation software were explored. Such methods like the combination of Design of Experiments (DOE) and Analysis of Variance (ANOVA) can serve as a prerequisite that determines the relationship between factors affecting a process and tests the differences between the relationships and their possible scope. Other improvements could be made by adopting a decentralized method of processing that better manages computing resources. 
Finally, during the review of collision-avoiding approaches, several critical aspects that weren’t taken into account were addressed. The research in the review papers don’t indicate: how the different approaches are influenced from different obstacle patterns; how do failed agents affect the rest of the agents; how the different approaches behave when a group is formed. These questions can be used in further research to improve the understanding of the topic and fill in a knowledge gap. 


	








Bibliography 

Vonolfen, S., Kofler, M., Beham, A., Affenzeller, M. and Achleitner, W. (2012) "Optimizing Assembly Line Supply By Integrating Warehouse Picking And Forklift Routing Using Simulation". Proceedings Of The Winter Simulation Conference 339

Ceylan, A., M.Gunal, M. and G. Bruzzone, A. (2012) "A New Approach To Simulation Modeling Of Unit-Load Warehouses". Proceedings Of The 2012 Symposium On Emerging Applications Of M&S In Industry And Academia Symposium 2 (ISBN: 978-1-61839-787-4)

Costantino, F., Curcio, D., Di Gravio, G. and Mirabelli, G. (2009) "A Simulation Based Approach For Warehouse Management". Proceedings Of The 2009 Spring Simulation Multiconference 136

Sundararajan, K. (2018) Design Of Experiments A Primer [online] available from <https://www.isixsigma.com/tools-templates/design-of-experiments-doe/design-experiments-%E2%90%93-primer/> [9 April 2018]

Ma, H. and Koenig, S. (2017) "AI Buzzwords Explained: Multi-Agent Path Finding (MAPF)". AI Matters 139 (3), 15-19

Ksontini, F., Guessoum, Z., Mandiau, R. and Espié, S. (2013) "Using Ego-Centered Affordances In Multi-Agent Traffic Simulation". Proceedings Of The 2013 International Conference On Autonomous Agents And Multi-Agent Systems (ISBN: 978-1-4503-1993-5), 151-158

Wang, C. (2011) "Massively Multi-Agent Pathfinding Made Tractable, Efficient, And With Completeness Guarantees". The 10Th International Conference On Autonomous Agents And Multiagent Systems 3, 1343-1344

Standley, T. (2010) "Finding Optimal Solutions To Cooperative Pathfinding Problems". Twenty-Fourth AAAI Conference On Artificial Intelligence (AAAI-10)

Silver, D. (2005) "Cooperative Pathfinding". AIIDE 117–122
